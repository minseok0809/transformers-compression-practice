{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMnkeLbnhAip"
      },
      "source": [
        "# [Project] BiBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3wErLdzL4tX"
      },
      "source": [
        "Introduction\n",
        "<br/>Development Environment\n",
        "<br/>BiBERT\n",
        "<br/>Conclusion\n",
        "<br/>Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>Dataset: SST-2\n",
        "<br><br>Task: Natural Language Processing\n",
        "<br><br>Method: Full Binarized Quantization, Straight Through Estimator (STE)\n",
        "<br><br>Compression: numpy.packbits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8cnzK8kL4wQ"
      },
      "source": [
        "## Development Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch==1.13.1  #cuda=11.8\n",
        "%pip install scipy\n",
        "%pip install seaborn\n",
        "%pip install openpyxl\n",
        "%pip install matplotlib\n",
        "%pip install tensorboard\n",
        "%pip install scikit-learn\n",
        "%pip install setuptools==59.5.0\n",
        "%pip install --no-cache-dir --extra-index-url https://pypi.nvidia.com pytorch-quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BiBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/deep_learning_bibert'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu117\n",
            "11.7\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_params = {\n",
        "    \"cola\":  {\"num_train_epochs\": 50, \"max_seq_length\": 64},\n",
        "    \"mnli\":  {\"num_train_epochs\": 6,  \"max_seq_length\": 128},\n",
        "    \"mrpc\":  {\"num_train_epochs\": 20, \"max_seq_length\": 128},\n",
        "    \"sst-2\": {\"num_train_epochs\": 10, \"max_seq_length\": 64},\n",
        "    \"sst-mini\": {\"num_train_epochs\": 10, \"max_seq_length\": 64},\n",
        "    \"sts-b\": {\"num_train_epochs\": 20, \"max_seq_length\": 128},\n",
        "    \"qqp\":   {\"num_train_epochs\": 6,  \"max_seq_length\": 128},\n",
        "    \"qnli\":  {\"num_train_epochs\": 10, \"max_seq_length\": 128},\n",
        "    \"rte\":   {\"num_train_epochs\": 20, \"max_seq_length\": 128},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|                                         | 0/4210 [00:00<?, ?it/s]/workspace/bibert_asym/transformer/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "Epoch 1: 100%|█████████████████████████████▉| 4209/4210 [10:31<00:00,  6.82it/s]Epoch 1 Step 4210 : 0.751\n",
            "Best : 0.751\n",
            "Epoch 1: 100%|██████████████████████████████| 4210/4210 [10:34<00:00,  6.64it/s]\n",
            "Epoch 2: 100%|█████████████████████████████▉| 4209/4210 [10:29<00:00,  6.67it/s]Epoch 2 Step 8420 : 0.817\n",
            "Best : 0.817\n",
            "Epoch 2: 100%|██████████████████████████████| 4210/4210 [10:32<00:00,  6.65it/s]\n",
            "Epoch 3: 100%|█████████████████████████████▉| 4209/4210 [10:41<00:00,  6.52it/s]Epoch 3 Step 12630 : 0.827\n",
            "Best : 0.827\n",
            "Epoch 3: 100%|██████████████████████████████| 4210/4210 [10:44<00:00,  6.53it/s]\n",
            "Epoch 4: 100%|█████████████████████████████▉| 4209/4210 [10:45<00:00,  6.28it/s]Epoch 4 Step 16840 : 0.847\n",
            "Best : 0.847\n",
            "Epoch 4: 100%|██████████████████████████████| 4210/4210 [10:48<00:00,  6.49it/s]\n",
            "Epoch 5: 100%|█████████████████████████████▉| 4209/4210 [10:39<00:00,  6.71it/s]Epoch 5 Step 21050 : 0.847\n",
            "Best : 0.847\n",
            "Epoch 5: 100%|██████████████████████████████| 4210/4210 [10:42<00:00,  6.56it/s]\n",
            "Epoch 6: 100%|█████████████████████████████▉| 4209/4210 [10:45<00:00,  6.59it/s]Epoch 6 Step 25260 : 0.853\n",
            "Best : 0.853\n",
            "Epoch 6: 100%|██████████████████████████████| 4210/4210 [10:47<00:00,  6.50it/s]\n",
            "Epoch 7: 100%|█████████████████████████████▉| 4209/4210 [10:51<00:00,  6.50it/s]Epoch 7 Step 29470 : 0.838\n",
            "Best : 0.853\n",
            "Epoch 7: 100%|██████████████████████████████| 4210/4210 [10:54<00:00,  6.44it/s]\n",
            "Epoch 8:   1%|▏                               | 29/4210 [00:04<10:59,  6.34it/s]Epoch 8 Step 29500 : 0.864\n",
            "Best : 0.864\n",
            "Epoch 8:   3%|▉                              | 129/4210 [00:22<10:23,  6.55it/s]Epoch 8 Step 29600 : 0.852\n",
            "Best : 0.864\n",
            "Epoch 8:   5%|█▋                             | 229/4210 [00:41<10:27,  6.35it/s]Epoch 8 Step 29700 : 0.861\n",
            "Best : 0.864\n",
            "Epoch 8:   8%|██▍                            | 329/4210 [00:59<10:01,  6.45it/s]Epoch 8 Step 29800 : 0.851\n",
            "Best : 0.864\n",
            "Epoch 8:  10%|███▏                           | 429/4210 [01:17<09:47,  6.44it/s]Epoch 8 Step 29900 : 0.861\n",
            "Best : 0.864\n",
            "Epoch 8:  13%|███▉                           | 529/4210 [01:35<09:20,  6.56it/s]Epoch 8 Step 30000 : 0.845\n",
            "Best : 0.864\n",
            "Epoch 8:  15%|████▋                          | 629/4210 [01:54<09:01,  6.61it/s]Epoch 8 Step 30100 : 0.867\n",
            "Best : 0.867\n",
            "Epoch 8:  17%|█████▎                         | 729/4210 [02:12<08:54,  6.52it/s]Epoch 8 Step 30200 : 0.874\n",
            "Best : 0.874\n",
            "Epoch 8:  20%|██████                         | 829/4210 [02:30<08:28,  6.65it/s]Epoch 8 Step 30300 : 0.869\n",
            "Best : 0.874\n",
            "Epoch 8:  22%|██████▊                        | 929/4210 [02:48<08:27,  6.46it/s]Epoch 8 Step 30400 : 0.849\n",
            "Best : 0.874\n",
            "Epoch 8:  24%|███████▎                      | 1029/4210 [03:06<08:01,  6.61it/s]Epoch 8 Step 30500 : 0.859\n",
            "Best : 0.874\n",
            "Epoch 8:  27%|████████                      | 1129/4210 [03:25<08:05,  6.35it/s]Epoch 8 Step 30600 : 0.859\n",
            "Best : 0.874\n",
            "Epoch 8:  29%|████████▊                     | 1229/4210 [03:44<07:58,  6.23it/s]Epoch 8 Step 30700 : 0.860\n",
            "Best : 0.874\n",
            "Epoch 8:  32%|█████████▍                    | 1329/4210 [04:02<07:25,  6.47it/s]Epoch 8 Step 30800 : 0.859\n",
            "Best : 0.874\n",
            "Epoch 8:  34%|██████████▏                   | 1429/4210 [04:20<07:06,  6.52it/s]Epoch 8 Step 30900 : 0.831\n",
            "Best : 0.874\n",
            "Epoch 8:  36%|██████████▉                   | 1529/4210 [04:39<06:49,  6.55it/s]Epoch 8 Step 31000 : 0.858\n",
            "Best : 0.874\n",
            "Epoch 8:  39%|███████████▌                  | 1629/4210 [04:57<06:47,  6.34it/s]Epoch 8 Step 31100 : 0.860\n",
            "Best : 0.874\n",
            "Epoch 8:  41%|████████████▎                 | 1729/4210 [05:16<06:28,  6.39it/s]Epoch 8 Step 31200 : 0.847\n",
            "Best : 0.874\n",
            "Epoch 8:  43%|█████████████                 | 1829/4210 [05:34<06:09,  6.45it/s]Epoch 8 Step 31300 : 0.864\n",
            "Best : 0.874\n",
            "Epoch 8:  46%|█████████████▋                | 1929/4210 [05:53<05:51,  6.48it/s]Epoch 8 Step 31400 : 0.862\n",
            "Best : 0.874\n",
            "Epoch 8:  48%|██████████████▍               | 2029/4210 [06:11<05:26,  6.67it/s]Epoch 8 Step 31500 : 0.856\n",
            "Best : 0.874\n",
            "Epoch 8:  51%|███████████████▏              | 2129/4210 [06:29<05:20,  6.50it/s]Epoch 8 Step 31600 : 0.866\n",
            "Best : 0.874\n",
            "Epoch 8:  53%|███████████████▉              | 2229/4210 [06:47<05:04,  6.51it/s]Epoch 8 Step 31700 : 0.853\n",
            "Best : 0.874\n",
            "Epoch 8:  55%|████████████████▌             | 2329/4210 [07:06<04:55,  6.37it/s]Epoch 8 Step 31800 : 0.864\n",
            "Best : 0.874\n",
            "Epoch 8:  58%|█████████████████▎            | 2429/4210 [07:25<04:36,  6.44it/s]Epoch 8 Step 31900 : 0.857\n",
            "Best : 0.874\n",
            "Epoch 8:  60%|██████████████████            | 2529/4210 [07:43<04:22,  6.40it/s]Epoch 8 Step 32000 : 0.864\n",
            "Best : 0.874\n",
            "Epoch 8:  62%|██████████████████▋           | 2629/4210 [08:01<04:01,  6.54it/s]Epoch 8 Step 32100 : 0.856\n",
            "Best : 0.874\n",
            "Epoch 8:  65%|███████████████████▍          | 2729/4210 [08:20<03:50,  6.43it/s]Epoch 8 Step 32200 : 0.873\n",
            "Best : 0.874\n",
            "Epoch 8:  67%|████████████████████▏         | 2829/4210 [08:39<03:39,  6.28it/s]Epoch 8 Step 32300 : 0.872\n",
            "Best : 0.874\n",
            "Epoch 8:  70%|████████████████████▊         | 2929/4210 [08:57<03:17,  6.49it/s]Epoch 8 Step 32400 : 0.864\n",
            "Best : 0.874\n",
            "Epoch 8:  72%|█████████████████████▌        | 3029/4210 [09:16<03:04,  6.39it/s]Epoch 8 Step 32500 : 0.861\n",
            "Best : 0.874\n",
            "Epoch 8:  74%|██████████████████████▎       | 3129/4210 [09:34<02:44,  6.56it/s]Epoch 8 Step 32600 : 0.860\n",
            "Best : 0.874\n",
            "Epoch 8:  77%|███████████████████████       | 3229/4210 [09:53<02:30,  6.53it/s]Epoch 8 Step 32700 : 0.857\n",
            "Best : 0.874\n",
            "Epoch 8:  79%|███████████████████████▋      | 3329/4210 [10:11<02:19,  6.32it/s]Epoch 8 Step 32800 : 0.861\n",
            "Best : 0.874\n",
            "Epoch 8:  81%|████████████████████████▍     | 3429/4210 [10:30<02:03,  6.34it/s]Epoch 8 Step 32900 : 0.858\n",
            "Best : 0.874\n",
            "Epoch 8:  84%|█████████████████████████▏    | 3529/4210 [10:48<01:45,  6.44it/s]Epoch 8 Step 33000 : 0.857\n",
            "Best : 0.874\n",
            "Epoch 8:  86%|█████████████████████████▊    | 3629/4210 [11:07<01:30,  6.39it/s]Epoch 8 Step 33100 : 0.851\n",
            "Best : 0.874\n",
            "Epoch 8:  89%|██████████████████████████▌   | 3729/4210 [11:25<01:16,  6.32it/s]Epoch 8 Step 33200 : 0.858\n",
            "Best : 0.874\n",
            "Epoch 8:  91%|███████████████████████████▎  | 3829/4210 [11:44<01:00,  6.32it/s]Epoch 8 Step 33300 : 0.861\n",
            "Best : 0.874\n",
            "Epoch 8:  93%|███████████████████████████▉  | 3929/4210 [12:02<00:43,  6.48it/s]Epoch 8 Step 33400 : 0.875\n",
            "Best : 0.875\n",
            "Epoch 8:  96%|████████████████████████████▋ | 4029/4210 [12:21<00:28,  6.36it/s]Epoch 8 Step 33500 : 0.866\n",
            "Best : 0.875\n",
            "Epoch 8:  98%|█████████████████████████████▍| 4129/4210 [12:39<00:12,  6.45it/s]Epoch 8 Step 33600 : 0.867\n",
            "Best : 0.875\n",
            "Epoch 8: 100%|█████████████████████████████▉| 4209/4210 [12:55<00:00,  6.38it/s]Epoch 8 Step 33680 : 0.851\n",
            "Best : 0.875\n",
            "Epoch 8: 100%|██████████████████████████████| 4210/4210 [12:58<00:00,  5.41it/s]\n",
            "Epoch 9:   0%|▏                               | 19/4210 [00:02<11:03,  6.32it/s]Epoch 9 Step 33700 : 0.865\n",
            "Best : 0.875\n",
            "Epoch 9:   3%|▉                              | 119/4210 [00:21<10:24,  6.55it/s]Epoch 9 Step 33800 : 0.875\n",
            "Best : 0.875\n",
            "Epoch 9:   5%|█▌                             | 219/4210 [00:39<09:59,  6.66it/s]Epoch 9 Step 33900 : 0.872\n",
            "Best : 0.875\n",
            "Epoch 9:   8%|██▎                            | 319/4210 [00:57<09:56,  6.52it/s]Epoch 9 Step 34000 : 0.864\n",
            "Best : 0.875\n",
            "Epoch 9:  10%|███                            | 419/4210 [01:16<09:46,  6.46it/s]Epoch 9 Step 34100 : 0.872\n",
            "Best : 0.875\n",
            "Epoch 9:  12%|███▊                           | 519/4210 [01:34<09:47,  6.29it/s]Epoch 9 Step 34200 : 0.858\n",
            "Best : 0.875\n",
            "Epoch 9:  15%|████▌                          | 619/4210 [01:53<09:17,  6.44it/s]Epoch 9 Step 34300 : 0.864\n",
            "Best : 0.875\n",
            "Epoch 9:  17%|█████▎                         | 719/4210 [02:11<08:44,  6.66it/s]Epoch 9 Step 34400 : 0.857\n",
            "Best : 0.875\n",
            "Epoch 9:  19%|██████                         | 819/4210 [02:30<08:34,  6.59it/s]Epoch 9 Step 34500 : 0.883\n",
            "Best : 0.883\n",
            "Epoch 9:  22%|██████▊                        | 919/4210 [02:48<08:25,  6.51it/s]Epoch 9 Step 34600 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9:  24%|███████▎                      | 1019/4210 [03:06<08:26,  6.30it/s]Epoch 9 Step 34700 : 0.875\n",
            "Best : 0.883\n",
            "Epoch 9:  27%|███████▉                      | 1119/4210 [03:25<07:59,  6.44it/s]Epoch 9 Step 34800 : 0.865\n",
            "Best : 0.883\n",
            "Epoch 9:  29%|████████▋                     | 1219/4210 [03:43<07:50,  6.36it/s]Epoch 9 Step 34900 : 0.870\n",
            "Best : 0.883\n",
            "Epoch 9:  31%|█████████▍                    | 1319/4210 [04:02<07:25,  6.48it/s]Epoch 9 Step 35000 : 0.875\n",
            "Best : 0.883\n",
            "Epoch 9:  34%|██████████                    | 1419/4210 [04:20<07:01,  6.62it/s]Epoch 9 Step 35100 : 0.846\n",
            "Best : 0.883\n",
            "Epoch 9:  36%|██████████▊                   | 1519/4210 [04:38<06:57,  6.45it/s]Epoch 9 Step 35200 : 0.869\n",
            "Best : 0.883\n",
            "Epoch 9:  38%|███████████▌                  | 1619/4210 [04:57<06:47,  6.35it/s]Epoch 9 Step 35300 : 0.873\n",
            "Best : 0.883\n",
            "Epoch 9:  41%|████████████▏                 | 1719/4210 [05:15<06:42,  6.18it/s]Epoch 9 Step 35400 : 0.864\n",
            "Best : 0.883\n",
            "Epoch 9:  43%|████████████▉                 | 1819/4210 [05:34<06:03,  6.57it/s]Epoch 9 Step 35500 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9:  46%|█████████████▋                | 1919/4210 [05:52<05:52,  6.49it/s]Epoch 9 Step 35600 : 0.858\n",
            "Best : 0.883\n",
            "Epoch 9:  48%|██████████████▍               | 2019/4210 [06:11<05:44,  6.37it/s]Epoch 9 Step 35700 : 0.859\n",
            "Best : 0.883\n",
            "Epoch 9:  50%|███████████████               | 2119/4210 [06:29<05:23,  6.47it/s]Epoch 9 Step 35800 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9:  53%|███████████████▊              | 2219/4210 [06:48<05:08,  6.46it/s]Epoch 9 Step 35900 : 0.868\n",
            "Best : 0.883\n",
            "Epoch 9:  55%|████████████████▌             | 2319/4210 [07:06<04:52,  6.48it/s]Epoch 9 Step 36000 : 0.858\n",
            "Best : 0.883\n",
            "Epoch 9:  57%|█████████████████▏            | 2419/4210 [07:24<04:31,  6.60it/s]Epoch 9 Step 36100 : 0.857\n",
            "Best : 0.883\n",
            "Epoch 9:  60%|█████████████████▉            | 2519/4210 [07:42<04:27,  6.31it/s]Epoch 9 Step 36200 : 0.852\n",
            "Best : 0.883\n",
            "Epoch 9:  62%|██████████████████▋           | 2619/4210 [08:01<04:16,  6.21it/s]Epoch 9 Step 36300 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9:  65%|███████████████████▍          | 2719/4210 [08:20<03:53,  6.39it/s]Epoch 9 Step 36400 : 0.874\n",
            "Best : 0.883\n",
            "Epoch 9:  67%|████████████████████          | 2819/4210 [08:38<03:29,  6.64it/s]Epoch 9 Step 36500 : 0.867\n",
            "Best : 0.883\n",
            "Epoch 9:  69%|████████████████████▊         | 2919/4210 [08:56<03:14,  6.63it/s]Epoch 9 Step 36600 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9:  72%|█████████████████████▌        | 3019/4210 [09:14<02:59,  6.63it/s]Epoch 9 Step 36700 : 0.872\n",
            "Best : 0.883\n",
            "Epoch 9:  74%|██████████████████████▏       | 3119/4210 [09:32<02:48,  6.48it/s]Epoch 9 Step 36800 : 0.858\n",
            "Best : 0.883\n",
            "Epoch 9:  76%|██████████████████████▉       | 3219/4210 [09:51<02:37,  6.30it/s]Epoch 9 Step 36900 : 0.864\n",
            "Best : 0.883\n",
            "Epoch 9:  79%|███████████████████████▋      | 3319/4210 [10:09<02:18,  6.42it/s]Epoch 9 Step 37000 : 0.851\n",
            "Best : 0.883\n",
            "Epoch 9:  81%|████████████████████████▎     | 3419/4210 [10:27<01:58,  6.65it/s]Epoch 9 Step 37100 : 0.868\n",
            "Best : 0.883\n",
            "Epoch 9:  84%|█████████████████████████     | 3519/4210 [10:45<01:45,  6.57it/s]Epoch 9 Step 37200 : 0.865\n",
            "Best : 0.883\n",
            "Epoch 9:  86%|█████████████████████████▊    | 3619/4210 [11:04<01:29,  6.61it/s]Epoch 9 Step 37300 : 0.883\n",
            "Best : 0.883\n",
            "Epoch 9:  88%|██████████████████████████▌   | 3719/4210 [11:22<01:14,  6.60it/s]Epoch 9 Step 37400 : 0.850\n",
            "Best : 0.883\n",
            "Epoch 9:  91%|███████████████████████████▏  | 3819/4210 [11:40<00:58,  6.64it/s]Epoch 9 Step 37500 : 0.873\n",
            "Best : 0.883\n",
            "Epoch 9:  93%|███████████████████████████▉  | 3919/4210 [11:58<00:43,  6.64it/s]Epoch 9 Step 37600 : 0.864\n",
            "Best : 0.883\n",
            "Epoch 9:  95%|████████████████████████████▋ | 4019/4210 [12:16<00:29,  6.57it/s]Epoch 9 Step 37700 : 0.868\n",
            "Best : 0.883\n",
            "Epoch 9:  98%|█████████████████████████████▎| 4119/4210 [12:35<00:14,  6.49it/s]Epoch 9 Step 37800 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 9: 100%|█████████████████████████████▉| 4209/4210 [12:52<00:00,  6.25it/s]Epoch 9 Step 37890 : 0.860\n",
            "Best : 0.883\n",
            "Epoch 9: 100%|██████████████████████████████| 4210/4210 [12:55<00:00,  5.43it/s]\n",
            "Epoch 10:   0%|                                | 9/4210 [00:01<10:48,  6.48it/s]Epoch 10 Step 37900 : 0.867\n",
            "Best : 0.883\n",
            "Epoch 10:   3%|▊                             | 109/4210 [00:19<10:10,  6.72it/s]Epoch 10 Step 38000 : 0.862\n",
            "Best : 0.883\n",
            "Epoch 10:   5%|█▍                            | 209/4210 [00:37<09:52,  6.75it/s]Epoch 10 Step 38100 : 0.865\n",
            "Best : 0.883\n",
            "Epoch 10:   7%|██▏                           | 309/4210 [00:55<09:54,  6.56it/s]Epoch 10 Step 38200 : 0.853\n",
            "Best : 0.883\n",
            "Epoch 10:  10%|██▉                           | 409/4210 [01:13<09:30,  6.66it/s]Epoch 10 Step 38300 : 0.876\n",
            "Best : 0.883\n",
            "Epoch 10:  12%|███▋                          | 509/4210 [01:31<09:26,  6.53it/s]Epoch 10 Step 38400 : 0.864\n",
            "Best : 0.883\n",
            "Epoch 10:  14%|████▎                         | 609/4210 [01:49<09:06,  6.59it/s]Epoch 10 Step 38500 : 0.872\n",
            "Best : 0.883\n",
            "Epoch 10:  17%|█████                         | 709/4210 [02:07<08:54,  6.55it/s]Epoch 10 Step 38600 : 0.872\n",
            "Best : 0.883\n",
            "Epoch 10:  19%|█████▊                        | 809/4210 [02:25<08:36,  6.59it/s]Epoch 10 Step 38700 : 0.884\n",
            "Best : 0.884\n",
            "Epoch 10:  22%|██████▍                       | 909/4210 [02:43<08:17,  6.63it/s]Epoch 10 Step 38800 : 0.859\n",
            "Best : 0.884\n",
            "Epoch 10:  24%|██████▉                      | 1009/4210 [03:01<07:58,  6.69it/s]Epoch 10 Step 38900 : 0.860\n",
            "Best : 0.884\n",
            "Epoch 10:  26%|███████▋                     | 1109/4210 [03:19<07:50,  6.59it/s]Epoch 10 Step 39000 : 0.867\n",
            "Best : 0.884\n",
            "Epoch 10:  29%|████████▎                    | 1209/4210 [03:37<07:39,  6.53it/s]Epoch 10 Step 39100 : 0.876\n",
            "Best : 0.884\n",
            "Epoch 10:  31%|█████████                    | 1309/4210 [03:55<07:07,  6.79it/s]Epoch 10 Step 39200 : 0.874\n",
            "Best : 0.884\n",
            "Epoch 10:  33%|█████████▋                   | 1409/4210 [04:14<07:07,  6.55it/s]Epoch 10 Step 39300 : 0.868\n",
            "Best : 0.884\n",
            "Epoch 10:  36%|██████████▍                  | 1509/4210 [04:32<06:54,  6.52it/s]Epoch 10 Step 39400 : 0.869\n",
            "Best : 0.884\n",
            "Epoch 10:  38%|███████████                  | 1609/4210 [04:50<06:37,  6.54it/s]Epoch 10 Step 39500 : 0.865\n",
            "Best : 0.884\n",
            "Epoch 10:  41%|███████████▊                 | 1709/4210 [05:08<06:31,  6.38it/s]Epoch 10 Step 39600 : 0.868\n",
            "Best : 0.884\n",
            "Epoch 10:  43%|████████████▍                | 1809/4210 [05:27<05:55,  6.76it/s]Epoch 10 Step 39700 : 0.874\n",
            "Best : 0.884\n",
            "Epoch 10:  45%|█████████████▏               | 1909/4210 [05:45<05:44,  6.68it/s]Epoch 10 Step 39800 : 0.866\n",
            "Best : 0.884\n",
            "Epoch 10:  48%|█████████████▊               | 2009/4210 [06:03<05:31,  6.65it/s]Epoch 10 Step 39900 : 0.867\n",
            "Best : 0.884\n",
            "Epoch 10:  50%|██████████████▌              | 2109/4210 [06:20<05:11,  6.74it/s]Epoch 10 Step 40000 : 0.866\n",
            "Best : 0.884\n",
            "Epoch 10:  52%|███████████████▏             | 2209/4210 [06:38<04:53,  6.82it/s]Epoch 10 Step 40100 : 0.859\n",
            "Best : 0.884\n",
            "Epoch 10:  55%|███████████████▉             | 2309/4210 [06:57<04:50,  6.55it/s]Epoch 10 Step 40200 : 0.858\n",
            "Best : 0.884\n",
            "Epoch 10:  57%|████████████████▌            | 2409/4210 [07:15<04:33,  6.59it/s]Epoch 10 Step 40300 : 0.866\n",
            "Best : 0.884\n",
            "Epoch 10:  60%|█████████████████▎           | 2509/4210 [07:33<04:15,  6.66it/s]Epoch 10 Step 40400 : 0.864\n",
            "Best : 0.884\n",
            "Epoch 10:  62%|█████████████████▉           | 2609/4210 [07:51<04:06,  6.50it/s]Epoch 10 Step 40500 : 0.869\n",
            "Best : 0.884\n",
            "Epoch 10:  64%|██████████████████▋          | 2709/4210 [08:10<03:54,  6.40it/s]Epoch 10 Step 40600 : 0.867\n",
            "Best : 0.884\n",
            "Epoch 10:  67%|███████████████████▎         | 2809/4210 [08:28<03:32,  6.59it/s]Epoch 10 Step 40700 : 0.853\n",
            "Best : 0.884\n",
            "Epoch 10:  69%|████████████████████         | 2909/4210 [08:46<03:19,  6.53it/s]Epoch 10 Step 40800 : 0.867\n",
            "Best : 0.884\n",
            "Epoch 10:  71%|████████████████████▋        | 3009/4210 [09:05<03:04,  6.51it/s]Epoch 10 Step 40900 : 0.860\n",
            "Best : 0.884\n",
            "Epoch 10:  74%|█████████████████████▍       | 3109/4210 [09:23<02:52,  6.37it/s]Epoch 10 Step 41000 : 0.870\n",
            "Best : 0.884\n",
            "Epoch 10:  76%|██████████████████████       | 3209/4210 [09:41<02:33,  6.51it/s]Epoch 10 Step 41100 : 0.866\n",
            "Best : 0.884\n",
            "Epoch 10:  79%|██████████████████████▊      | 3309/4210 [10:00<02:19,  6.46it/s]Epoch 10 Step 41200 : 0.870\n",
            "Best : 0.884\n",
            "Epoch 10:  81%|███████████████████████▍     | 3409/4210 [10:18<02:06,  6.32it/s]Epoch 10 Step 41300 : 0.860\n",
            "Best : 0.884\n",
            "Epoch 10:  83%|████████████████████████▏    | 3509/4210 [10:37<01:51,  6.31it/s]Epoch 10 Step 41400 : 0.858\n",
            "Best : 0.884\n",
            "Epoch 10:  86%|████████████████████████▊    | 3609/4210 [10:56<01:34,  6.37it/s]Epoch 10 Step 41500 : 0.861\n",
            "Best : 0.884\n",
            "Epoch 10:  88%|█████████████████████████▌   | 3709/4210 [11:14<01:15,  6.65it/s]Epoch 10 Step 41600 : 0.872\n",
            "Best : 0.884\n",
            "Epoch 10:  90%|██████████████████████████▏  | 3809/4210 [11:32<01:01,  6.57it/s]Epoch 10 Step 41700 : 0.864\n",
            "Best : 0.884\n",
            "Epoch 10:  93%|██████████████████████████▉  | 3909/4210 [11:50<00:45,  6.60it/s]Epoch 10 Step 41800 : 0.869\n",
            "Best : 0.884\n",
            "Epoch 10:  95%|███████████████████████████▌ | 4009/4210 [12:09<00:30,  6.65it/s]Epoch 10 Step 41900 : 0.851\n",
            "Best : 0.884\n",
            "Epoch 10:  98%|████████████████████████████▎| 4109/4210 [12:27<00:15,  6.64it/s]Epoch 10 Step 42000 : 0.875\n",
            "Best : 0.884\n",
            "Epoch 10: 100%|████████████████████████████▉| 4201/4210 [12:44<00:01,  6.35it/s]01/28 11:34:07 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4202/4210 [12:44<00:01,  6.30it/s]01/28 11:34:07 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4203/4210 [12:44<00:01,  6.24it/s]01/28 11:34:07 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4204/4210 [12:45<00:00,  6.23it/s]01/28 11:34:07 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4205/4210 [12:45<00:00,  6.20it/s]01/28 11:34:08 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4206/4210 [12:45<00:00,  6.19it/s]01/28 11:34:08 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4207/4210 [12:45<00:00,  6.19it/s]01/28 11:34:08 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4208/4210 [12:45<00:00,  6.25it/s]01/28 11:34:08 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10: 100%|████████████████████████████▉| 4209/4210 [12:45<00:00,  6.28it/s]01/28 11:34:08 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 10 Step 42100 : 0.864\n",
            "Best : 0.884\n",
            "Epoch 10: 100%|█████████████████████████████| 4210/4210 [12:49<00:00,  5.47it/s]\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/htqin/BiBERT/blob/main/scripts/train_sst-2.sh\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "!python quant_task_glue.py \\\n",
        "    --data_dir 'data' \\\n",
        "    --model_dir 'models/bert-base-uncased' \\\n",
        "    --task_name 'sst-2' \\\n",
        "    --output_dir 'output/sst-2' \\\n",
        "    --log_dir 'log/bibert' \\\n",
        "    --seed 42 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --eval_step 100 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --expriement_number 0 \\\n",
        "    --random_ratio 0.0 \\\n",
        "    --input_bits 1 \\\n",
        "    --weight_bits 1 \\\n",
        "    --embedding_bits 1 \\\n",
        "    --batch_size 16 \\\n",
        "    --pred_distill \\\n",
        "    --intermediate_distill \\\n",
        "    --value_distill \\\n",
        "    --key_distill \\\n",
        "    --query_distill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|                                          | 0/230 [00:00<?, ?it/s]/workspace/bibert_asym/transformer/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "Epoch 1: 100%|███████████████████████████████▊| 229/230 [00:37<00:00,  6.07it/s]Epoch 1 Step 230 : 0.684\n",
            "Best : 0.684\n",
            "Epoch 1: 100%|████████████████████████████████| 230/230 [00:39<00:00,  5.86it/s]\n",
            "Epoch 2: 100%|███████████████████████████████▊| 229/230 [00:37<00:00,  6.10it/s]Epoch 2 Step 460 : 0.684\n",
            "Best : 0.684\n",
            "Epoch 2: 100%|████████████████████████████████| 230/230 [00:39<00:00,  5.86it/s]\n",
            "Epoch 3: 100%|███████████████████████████████▊| 229/230 [00:37<00:00,  6.08it/s]Epoch 3 Step 690 : 0.684\n",
            "Best : 0.684\n",
            "Epoch 3: 100%|████████████████████████████████| 230/230 [00:39<00:00,  5.85it/s]\n",
            "Epoch 4: 100%|███████████████████████████████▊| 229/230 [00:37<00:00,  6.08it/s]Epoch 4 Step 920 : 0.684\n",
            "Best : 0.684\n",
            "Epoch 4: 100%|████████████████████████████████| 230/230 [00:39<00:00,  5.85it/s]\n",
            "Epoch 5: 100%|███████████████████████████████▊| 229/230 [00:37<00:00,  6.07it/s]Epoch 5 Step 1150 : 0.684\n",
            "Best : 0.684\n",
            "Epoch 5: 100%|████████████████████████████████| 230/230 [00:39<00:00,  5.82it/s]\n",
            "Epoch 6:  21%|███████                          | 49/230 [00:08<00:29,  6.09it/s]Epoch 6 Step 1200 : 0.679\n",
            "Best : 0.684\n",
            "Epoch 6:  65%|████████████████████▋           | 149/230 [00:26<00:13,  6.11it/s]Epoch 6 Step 1300 : 0.686\n",
            "Best : 0.686\n",
            "Epoch 6: 100%|███████████████████████████████▊| 229/230 [00:40<00:00,  6.12it/s]Epoch 6 Step 1380 : 0.703\n",
            "Best : 0.703\n",
            "Epoch 6: 100%|████████████████████████████████| 230/230 [00:42<00:00,  5.46it/s]\n",
            "Epoch 7:   8%|██▋                              | 19/230 [00:03<00:34,  6.08it/s]Epoch 7 Step 1400 : 0.667\n",
            "Best : 0.703\n",
            "Epoch 7:  52%|████████████████▌               | 119/230 [00:20<00:18,  6.00it/s]Epoch 7 Step 1500 : 0.637\n",
            "Best : 0.703\n",
            "Epoch 7:  95%|██████████████████████████████▍ | 219/230 [00:38<00:01,  6.12it/s]Epoch 7 Step 1600 : 0.679\n",
            "Best : 0.703\n",
            "Epoch 7: 100%|███████████████████████████████▊| 229/230 [00:41<00:00,  5.53it/s]Epoch 7 Step 1610 : 0.679\n",
            "Best : 0.703\n",
            "Epoch 7: 100%|████████████████████████████████| 230/230 [00:43<00:00,  5.28it/s]\n",
            "Epoch 8:  39%|████████████▊                    | 89/230 [00:14<00:23,  6.09it/s]Epoch 8 Step 1700 : 0.676\n",
            "Best : 0.703\n",
            "Epoch 8:  82%|██████████████████████████▎     | 189/230 [00:32<00:06,  6.09it/s]Epoch 8 Step 1800 : 0.689\n",
            "Best : 0.703\n",
            "Epoch 8: 100%|███████████████████████████████▊| 229/230 [00:40<00:00,  6.12it/s]Epoch 8 Step 1840 : 0.694\n",
            "Best : 0.703\n",
            "Epoch 8: 100%|████████████████████████████████| 230/230 [00:42<00:00,  5.46it/s]\n",
            "Epoch 9:  26%|████████▍                        | 59/230 [00:09<00:28,  6.07it/s]Epoch 9 Step 1900 : 0.672\n",
            "Best : 0.703\n",
            "Epoch 9:  69%|██████████████████████          | 159/230 [00:27<00:11,  6.10it/s]Epoch 9 Step 2000 : 0.632\n",
            "Best : 0.703\n",
            "Epoch 9: 100%|███████████████████████████████▊| 229/230 [00:40<00:00,  6.10it/s]Epoch 9 Step 2070 : 0.699\n",
            "Best : 0.703\n",
            "Epoch 9: 100%|████████████████████████████████| 230/230 [00:42<00:00,  5.44it/s]\n",
            "Epoch 10:  13%|████                            | 29/230 [00:04<00:33,  6.06it/s]Epoch 10 Step 2100 : 0.694\n",
            "Best : 0.703\n",
            "Epoch 10:  56%|█████████████████▍             | 129/230 [00:22<00:16,  6.09it/s]Epoch 10 Step 2200 : 0.630\n",
            "Best : 0.703\n",
            "Epoch 10: 100%|██████████████████████████████▊| 229/230 [00:40<00:00,  6.10it/s]Epoch 10 Step 2300 : 0.679\n",
            "Best : 0.703\n",
            "Epoch 10: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.45it/s]\n",
            "Epoch 11:  43%|█████████████▊                  | 99/230 [00:16<00:21,  6.03it/s]Epoch 11 Step 2400 : 0.620\n",
            "Best : 0.703\n",
            "Epoch 11:  87%|██████████████████████████▊    | 199/230 [00:34<00:05,  6.09it/s]Epoch 11 Step 2500 : 0.706\n",
            "Best : 0.706\n",
            "Epoch 11: 100%|██████████████████████████████▊| 229/230 [00:40<00:00,  6.05it/s]Epoch 11 Step 2530 : 0.694\n",
            "Best : 0.706\n",
            "Epoch 11: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.45it/s]\n",
            "Epoch 12:  30%|█████████▌                      | 69/230 [00:11<00:26,  6.07it/s]Epoch 12 Step 2600 : 0.689\n",
            "Best : 0.706\n",
            "Epoch 12:  73%|██████████████████████▊        | 169/230 [00:29<00:10,  5.97it/s]Epoch 12 Step 2700 : 0.701\n",
            "Best : 0.706\n",
            "Epoch 12: 100%|██████████████████████████████▊| 229/230 [00:40<00:00,  6.04it/s]Epoch 12 Step 2760 : 0.686\n",
            "Best : 0.706\n",
            "Epoch 12: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.42it/s]\n",
            "Epoch 13:  17%|█████▍                          | 39/230 [00:06<00:31,  6.05it/s]Epoch 13 Step 2800 : 0.691\n",
            "Best : 0.706\n",
            "Epoch 13:  60%|██████████████████▋            | 139/230 [00:24<00:15,  6.01it/s]Epoch 13 Step 2900 : 0.684\n",
            "Best : 0.706\n",
            "Epoch 13: 100%|██████████████████████████████▊| 229/230 [00:40<00:00,  6.10it/s]Epoch 13 Step 2990 : 0.708\n",
            "Best : 0.708\n",
            "Epoch 13: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.44it/s]\n",
            "Epoch 14:   4%|█▎                               | 9/230 [00:01<00:36,  6.06it/s]Epoch 14 Step 3000 : 0.701\n",
            "Best : 0.708\n",
            "Epoch 14:  47%|██████████████▋                | 109/230 [00:19<00:19,  6.10it/s]Epoch 14 Step 3100 : 0.708\n",
            "Best : 0.708\n",
            "Epoch 14:  91%|████████████████████████████▏  | 209/230 [00:37<00:03,  6.02it/s]Epoch 14 Step 3200 : 0.618\n",
            "Best : 0.708\n",
            "Epoch 14: 100%|██████████████████████████████▊| 229/230 [00:42<00:00,  6.02it/s]Epoch 14 Step 3220 : 0.681\n",
            "Best : 0.708\n",
            "Epoch 14: 100%|███████████████████████████████| 230/230 [00:43<00:00,  5.27it/s]\n",
            "Epoch 15:  34%|██████████▉                     | 79/230 [00:13<00:25,  5.98it/s]Epoch 15 Step 3300 : 0.723\n",
            "Best : 0.723\n",
            "Epoch 15:  78%|████████████████████████▏      | 179/230 [00:31<00:08,  6.12it/s]Epoch 15 Step 3400 : 0.699\n",
            "Best : 0.723\n",
            "Epoch 15: 100%|██████████████████████████████▊| 229/230 [00:40<00:00,  6.11it/s]Epoch 15 Step 3450 : 0.701\n",
            "Best : 0.723\n",
            "Epoch 15: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.42it/s]\n",
            "Epoch 16:  21%|██████▊                         | 49/230 [00:08<00:30,  5.95it/s]Epoch 16 Step 3500 : 0.713\n",
            "Best : 0.723\n",
            "Epoch 16:  65%|████████████████████           | 149/230 [00:26<00:13,  5.90it/s]Epoch 16 Step 3600 : 0.686\n",
            "Best : 0.723\n",
            "Epoch 16: 100%|██████████████████████████████▊| 229/230 [00:41<00:00,  5.96it/s]Epoch 16 Step 3680 : 0.679\n",
            "Best : 0.723\n",
            "Epoch 16: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.37it/s]\n",
            "Epoch 17:   8%|██▋                             | 19/230 [00:03<00:35,  5.96it/s]Epoch 17 Step 3700 : 0.664\n",
            "Best : 0.723\n",
            "Epoch 17:  52%|████████████████               | 119/230 [00:21<00:18,  6.00it/s]Epoch 17 Step 3800 : 0.681\n",
            "Best : 0.723\n",
            "Epoch 17:  95%|█████████████████████████████▌ | 219/230 [00:39<00:01,  6.04it/s]Epoch 17 Step 3900 : 0.696\n",
            "Best : 0.723\n",
            "Epoch 17: 100%|██████████████████████████████▊| 229/230 [00:42<00:00,  5.45it/s]Epoch 17 Step 3910 : 0.703\n",
            "Best : 0.723\n",
            "Epoch 17: 100%|███████████████████████████████| 230/230 [00:44<00:00,  5.20it/s]\n",
            "Epoch 18:  39%|████████████▍                   | 89/230 [00:15<00:23,  5.91it/s]Epoch 18 Step 4000 : 0.674\n",
            "Best : 0.723\n",
            "Epoch 18:  82%|█████████████████████████▍     | 189/230 [00:33<00:06,  5.95it/s]Epoch 18 Step 4100 : 0.686\n",
            "Best : 0.723\n",
            "Epoch 18: 100%|██████████████████████████████▊| 229/230 [00:41<00:00,  5.98it/s]Epoch 18 Step 4140 : 0.681\n",
            "Best : 0.723\n",
            "Epoch 18: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.36it/s]\n",
            "Epoch 19:  26%|████████▏                       | 59/230 [00:09<00:29,  5.87it/s]Epoch 19 Step 4200 : 0.701\n",
            "Best : 0.723\n",
            "Epoch 19:  69%|█████████████████████▍         | 159/230 [00:28<00:11,  6.08it/s]Epoch 19 Step 4300 : 0.696\n",
            "Best : 0.723\n",
            "Epoch 19: 100%|██████████████████████████████▊| 229/230 [00:41<00:00,  6.08it/s]Epoch 19 Step 4370 : 0.672\n",
            "Best : 0.723\n",
            "Epoch 19: 100%|███████████████████████████████| 230/230 [00:42<00:00,  5.37it/s]\n",
            "Epoch 20:  13%|████                            | 29/230 [00:04<00:33,  5.96it/s]Epoch 20 Step 4400 : 0.694\n",
            "Best : 0.723\n",
            "Epoch 20:  56%|█████████████████▍             | 129/230 [00:23<00:17,  5.91it/s]Epoch 20 Step 4500 : 0.703\n",
            "Best : 0.723\n",
            "Epoch 20:  92%|████████████████████████████▍  | 211/230 [00:38<00:03,  5.88it/s]01/28 09:38:45 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  92%|████████████████████████████▌  | 212/230 [00:38<00:03,  5.88it/s]01/28 09:38:45 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  93%|████████████████████████████▋  | 213/230 [00:38<00:02,  5.88it/s]01/28 09:38:46 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  93%|████████████████████████████▊  | 214/230 [00:38<00:02,  5.87it/s]01/28 09:38:46 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  93%|████████████████████████████▉  | 215/230 [00:39<00:02,  5.87it/s]01/28 09:38:46 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  94%|█████████████████████████████  | 216/230 [00:39<00:02,  5.87it/s]01/28 09:38:46 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  94%|█████████████████████████████▏ | 217/230 [00:39<00:02,  5.86it/s]01/28 09:38:46 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  95%|█████████████████████████████▍ | 218/230 [00:39<00:02,  5.92it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  95%|█████████████████████████████▌ | 219/230 [00:39<00:01,  5.90it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  96%|█████████████████████████████▋ | 220/230 [00:39<00:01,  5.90it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  96%|█████████████████████████████▊ | 221/230 [00:40<00:01,  5.89it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  97%|█████████████████████████████▉ | 222/230 [00:40<00:01,  5.89it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  97%|██████████████████████████████ | 223/230 [00:40<00:01,  5.94it/s]01/28 09:38:47 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  97%|██████████████████████████████▏| 224/230 [00:40<00:01,  5.92it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  98%|██████████████████████████████▎| 225/230 [00:40<00:00,  5.90it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  98%|██████████████████████████████▍| 226/230 [00:40<00:00,  5.88it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  99%|██████████████████████████████▌| 227/230 [00:41<00:00,  5.81it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  99%|██████████████████████████████▋| 228/230 [00:41<00:00,  5.83it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20: 100%|██████████████████████████████▊| 229/230 [00:41<00:00,  5.84it/s]01/28 09:38:48 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20 Step 4600 : 0.684\n",
            "Best : 0.723\n",
            "Epoch 20: 100%|███████████████████████████████| 230/230 [00:43<00:00,  5.33it/s]\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/htqin/BiBERT/blob/main/scripts/train_mrpc.sh\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "!python quant_task_glue.py \\\n",
        "    --data_dir 'data' \\\n",
        "    --model_dir 'models/bert-base-uncased' \\\n",
        "    --task_name 'mrpc' \\\n",
        "    --output_dir 'output/mrpc' \\\n",
        "    --log_dir 'log/bibert' \\\n",
        "    --seed 42 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --eval_step 100 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --expriement_number 0 \\\n",
        "    --random_ratio 0.0 \\\n",
        "    --input_bits 1 \\\n",
        "    --weight_bits 1 \\\n",
        "    --embedding_bits 1 \\\n",
        "    --batch_size 16 \\\n",
        "    --pred_distill \\\n",
        "    --intermediate_distill \\\n",
        "    --value_distill \\\n",
        "    --key_distill \\\n",
        "    --query_distill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|                                          | 0/141 [00:00<?, ?it/s]/workspace/bibert_original/transformer/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "Epoch 1:  70%|███████████████████████▏         | 99/141 [00:13<00:05,  7.47it/s]Epoch 1 Step 100 : 0.470\n",
            "Best : 0.470\n",
            "Epoch 1:  99%|███████████████████████████████▌| 139/141 [00:19<00:00,  7.19it/s]Epoch 1 Step 140 : 0.482\n",
            "Best : 0.482\n",
            "Epoch 1:  99%|███████████████████████████████▊| 140/141 [00:20<00:00,  2.44it/s]Epoch 1 Step 141 : 0.494\n",
            "Best : 0.494\n",
            "Epoch 1: 100%|████████████████████████████████| 141/141 [00:21<00:00,  6.45it/s]\n",
            "Epoch 2:  41%|█████████████▌                   | 58/141 [00:07<00:11,  7.39it/s]Epoch 2 Step 200 : 0.506\n",
            "Best : 0.506\n",
            "Epoch 2:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.45it/s]Epoch 2 Step 282 : 0.474\n",
            "Best : 0.506\n",
            "Epoch 2: 100%|████████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
            "Epoch 3:  12%|███▉                             | 17/141 [00:02<00:16,  7.51it/s]Epoch 3 Step 300 : 0.482\n",
            "Best : 0.506\n",
            "Epoch 3:  83%|██████████████████████████▌     | 117/141 [00:15<00:03,  7.52it/s]Epoch 3 Step 400 : 0.554\n",
            "Best : 0.554\n",
            "Epoch 3:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.55it/s]Epoch 3 Step 423 : 0.490\n",
            "Best : 0.554\n",
            "Epoch 3: 100%|████████████████████████████████| 141/141 [00:20<00:00,  6.87it/s]\n",
            "Epoch 4:  54%|█████████████████▊               | 76/141 [00:10<00:08,  7.40it/s]Epoch 4 Step 500 : 0.562\n",
            "Best : 0.562\n",
            "Epoch 4:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.55it/s]Epoch 4 Step 564 : 0.506\n",
            "Best : 0.562\n",
            "Epoch 4: 100%|████████████████████████████████| 141/141 [00:20<00:00,  7.00it/s]\n",
            "Epoch 5:  25%|████████▏                        | 35/141 [00:04<00:14,  7.43it/s]Epoch 5 Step 600 : 0.490\n",
            "Best : 0.562\n",
            "Epoch 5:  96%|██████████████████████████████▋ | 135/141 [00:18<00:00,  7.47it/s]Epoch 5 Step 700 : 0.490\n",
            "Best : 0.562\n",
            "Epoch 5:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  5.95it/s]Epoch 5 Step 705 : 0.482\n",
            "Best : 0.562\n",
            "Epoch 5: 100%|████████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
            "Epoch 6:  67%|██████████████████████           | 94/141 [00:12<00:06,  7.48it/s]Epoch 6 Step 800 : 0.438\n",
            "Best : 0.562\n",
            "Epoch 6:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.56it/s]Epoch 6 Step 846 : 0.534\n",
            "Best : 0.562\n",
            "Epoch 6: 100%|████████████████████████████████| 141/141 [00:19<00:00,  7.09it/s]\n",
            "Epoch 7:  38%|████████████▍                    | 53/141 [00:07<00:11,  7.52it/s]Epoch 7 Step 900 : 0.510\n",
            "Best : 0.562\n",
            "Epoch 7:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.55it/s]Epoch 7 Step 987 : 0.490\n",
            "Best : 0.562\n",
            "Epoch 7: 100%|████████████████████████████████| 141/141 [00:19<00:00,  7.13it/s]\n",
            "Epoch 8:   9%|██▊                              | 12/141 [00:01<00:17,  7.49it/s]Epoch 8 Step 1000 : 0.522\n",
            "Best : 0.562\n",
            "Epoch 8:  79%|█████████████████████████▍      | 112/141 [00:15<00:03,  7.52it/s]Epoch 8 Step 1100 : 0.502\n",
            "Best : 0.562\n",
            "Epoch 8:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.46it/s]Epoch 8 Step 1128 : 0.514\n",
            "Best : 0.562\n",
            "Epoch 8: 100%|████████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
            "Epoch 9:  50%|████████████████▌                | 71/141 [00:09<00:09,  7.53it/s]Epoch 9 Step 1200 : 0.514\n",
            "Best : 0.562\n",
            "Epoch 9:  99%|███████████████████████████████▊| 140/141 [00:19<00:00,  7.57it/s]Epoch 9 Step 1269 : 0.538\n",
            "Best : 0.562\n",
            "Epoch 9: 100%|████████████████████████████████| 141/141 [00:19<00:00,  7.18it/s]\n",
            "Epoch 10:  21%|██████▊                         | 30/141 [00:03<00:14,  7.52it/s]Epoch 10 Step 1300 : 0.546\n",
            "Best : 0.562\n",
            "Epoch 10:  92%|████████████████████████████▌  | 130/141 [00:17<00:01,  7.45it/s]Epoch 10 Step 1400 : 0.522\n",
            "Best : 0.562\n",
            "Epoch 10:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.08it/s]Epoch 10 Step 1410 : 0.510\n",
            "Best : 0.562\n",
            "Epoch 10: 100%|███████████████████████████████| 141/141 [00:20<00:00,  7.04it/s]\n",
            "Epoch 11:  63%|████████████████████▏           | 89/141 [00:11<00:06,  7.45it/s]Epoch 11 Step 1500 : 0.462\n",
            "Best : 0.562\n",
            "Epoch 11:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.49it/s]Epoch 11 Step 1551 : 0.474\n",
            "Best : 0.562\n",
            "Epoch 11: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.13it/s]\n",
            "Epoch 12:  34%|██████████▉                     | 48/141 [00:06<00:12,  7.45it/s]Epoch 12 Step 1600 : 0.522\n",
            "Best : 0.562\n",
            "Epoch 12:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.42it/s]Epoch 12 Step 1692 : 0.522\n",
            "Best : 0.562\n",
            "Epoch 12: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.17it/s]\n",
            "Epoch 13:   5%|█▋                               | 7/141 [00:00<00:17,  7.53it/s]Epoch 13 Step 1700 : 0.462\n",
            "Best : 0.562\n",
            "Epoch 13:  76%|███████████████████████▌       | 107/141 [00:14<00:04,  7.55it/s]Epoch 13 Step 1800 : 0.510\n",
            "Best : 0.562\n",
            "Epoch 13:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.30it/s]Epoch 13 Step 1833 : 0.510\n",
            "Best : 0.562\n",
            "Epoch 13: 100%|███████████████████████████████| 141/141 [00:20<00:00,  7.01it/s]\n",
            "Epoch 14:  47%|██████████████▉                 | 66/141 [00:08<00:10,  7.50it/s]Epoch 14 Step 1900 : 0.474\n",
            "Best : 0.562\n",
            "Epoch 14:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.59it/s]Epoch 14 Step 1974 : 0.482\n",
            "Best : 0.562\n",
            "Epoch 14: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.16it/s]\n",
            "Epoch 15:  18%|█████▋                          | 25/141 [00:03<00:15,  7.37it/s]Epoch 15 Step 2000 : 0.514\n",
            "Best : 0.562\n",
            "Epoch 15:  89%|███████████████████████████▍   | 125/141 [00:17<00:02,  7.37it/s]Epoch 15 Step 2100 : 0.502\n",
            "Best : 0.562\n",
            "Epoch 15:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.45it/s]Epoch 15 Step 2115 : 0.526\n",
            "Best : 0.562\n",
            "Epoch 15: 100%|███████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
            "Epoch 16:  60%|███████████████████             | 84/141 [00:11<00:07,  7.39it/s]Epoch 16 Step 2200 : 0.506\n",
            "Best : 0.562\n",
            "Epoch 16:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.49it/s]Epoch 16 Step 2256 : 0.498\n",
            "Best : 0.562\n",
            "Epoch 16: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.08it/s]\n",
            "Epoch 17:  30%|█████████▊                      | 43/141 [00:05<00:13,  7.46it/s]Epoch 17 Step 2300 : 0.450\n",
            "Best : 0.562\n",
            "Epoch 17:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.46it/s]Epoch 17 Step 2397 : 0.462\n",
            "Best : 0.562\n",
            "Epoch 17: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.09it/s]\n",
            "Epoch 18:   1%|▍                                | 2/141 [00:00<00:19,  7.27it/s]Epoch 18 Step 2400 : 0.478\n",
            "Best : 0.562\n",
            "Epoch 18:  72%|██████████████████████▍        | 102/141 [00:14<00:05,  7.53it/s]Epoch 18 Step 2500 : 0.502\n",
            "Best : 0.562\n",
            "Epoch 18:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.53it/s]Epoch 18 Step 2538 : 0.542\n",
            "Best : 0.562\n",
            "Epoch 18: 100%|███████████████████████████████| 141/141 [00:20<00:00,  7.02it/s]\n",
            "Epoch 19:  43%|█████████████▊                  | 61/141 [00:08<00:10,  7.48it/s]Epoch 19 Step 2600 : 0.522\n",
            "Best : 0.562\n",
            "Epoch 19:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.44it/s]Epoch 19 Step 2679 : 0.554\n",
            "Best : 0.562\n",
            "Epoch 19: 100%|███████████████████████████████| 141/141 [00:19<00:00,  7.18it/s]\n",
            "Epoch 20:  14%|████▌                           | 20/141 [00:02<00:16,  7.40it/s]Epoch 20 Step 2700 : 0.518\n",
            "Best : 0.562\n",
            "Epoch 20:  85%|██████████████████████████▍    | 120/141 [00:16<00:02,  7.35it/s]Epoch 20 Step 2800 : 0.502\n",
            "Best : 0.562\n",
            "Epoch 20:  87%|██████████████████████████▊    | 122/141 [00:17<00:04,  4.32it/s]01/29 04:32:09 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  87%|███████████████████████████    | 123/141 [00:17<00:03,  4.92it/s]01/29 04:32:09 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  88%|███████████████████████████▎   | 124/141 [00:17<00:03,  5.49it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  89%|███████████████████████████▍   | 125/141 [00:17<00:02,  5.98it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  89%|███████████████████████████▋   | 126/141 [00:17<00:02,  6.31it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  90%|███████████████████████████▉   | 127/141 [00:17<00:02,  6.58it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  91%|████████████████████████████▏  | 128/141 [00:18<00:01,  6.78it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  91%|████████████████████████████▎  | 129/141 [00:18<00:01,  6.99it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  92%|████████████████████████████▌  | 130/141 [00:18<00:01,  7.08it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  93%|████████████████████████████▊  | 131/141 [00:18<00:01,  7.15it/s]01/29 04:32:10 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  94%|█████████████████████████████  | 132/141 [00:18<00:01,  7.20it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  94%|█████████████████████████████▏ | 133/141 [00:18<00:01,  7.30it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  95%|█████████████████████████████▍ | 134/141 [00:18<00:00,  7.31it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  96%|█████████████████████████████▋ | 135/141 [00:19<00:00,  7.29it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  96%|█████████████████████████████▉ | 136/141 [00:19<00:00,  7.36it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  97%|██████████████████████████████ | 137/141 [00:19<00:00,  7.42it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  98%|██████████████████████████████▎| 138/141 [00:19<00:00,  7.46it/s]01/29 04:32:11 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  99%|██████████████████████████████▌| 139/141 [00:19<00:00,  7.40it/s]01/29 04:32:12 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20:  99%|██████████████████████████████▊| 140/141 [00:19<00:00,  7.36it/s]01/29 04:32:12 PM Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
            "Epoch 20 Step 2820 : 0.502\n",
            "Best : 0.562\n",
            "Epoch 20: 100%|███████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/htqin/BiBERT/blob/main/scripts/train_rte.sh\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "!python quant_task_glue.py \\\n",
        "    --data_dir 'data' \\\n",
        "    --model_dir 'models/bert-base-uncased' \\\n",
        "    --task_name 'rte' \\\n",
        "    --output_dir 'output/rte' \\\n",
        "    --log_dir 'log/bibert' \\\n",
        "    --seed 42 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --eval_step 100 \\\n",
        "    --learning_rate 1e-5 \\\n",
        "    --expriement_number 0 \\\n",
        "    --random_ratio 0.0 \\\n",
        "    --input_bits 1 \\\n",
        "    --weight_bits 1 \\\n",
        "    --embedding_bits 1 \\\n",
        "    --batch_size 16 \\\n",
        "    --pred_distill \\\n",
        "    --intermediate_distill \\\n",
        "    --value_distill \\\n",
        "    --key_distill \\\n",
        "    --query_distill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Paper**\n",
        "<br/>[Haotong et al. BiBERT: Accurate Fully Binarized BERT, ICLR, 2022](https://arxiv.org/abs/2010.11929)\n",
        "\n",
        "<br/>**Github**\n",
        "<br/>[htqin/BiBERT](https://github.com/htqin/BiBERT)\n",
        "<br/>[Zhen-Dong/BitPack](https://github.com/Zhen-Dong/BitPack)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
